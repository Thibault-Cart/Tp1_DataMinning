{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71f9d149",
   "metadata": {},
   "source": [
    "# Entraînement et évaluation de Naive Bayes (avec des attributs prédictifs quantitatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2486efef",
   "metadata": {},
   "source": [
    "Comme d'habitude, nous travaillerons avec l'ensemble de données iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665cbe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mettre le paquet Naive Bayes à disposition\n",
    "library(\"e1071\")\n",
    "\n",
    "\n",
    "#for latex parsing of equations\n",
    "library(\"latex2exp\")\n",
    "\n",
    "#read data\n",
    "# avec colClasses, nous contrôlons explicitement les types des différentes variables, \n",
    "# les valeurs qui nous intéressent le plus sont \n",
    "# factor: variables qualitatives\n",
    "# numeric: pour les variables quantitatives\n",
    "myData<- read.table(\"iris.csv\",header=T,sep=\",\",colClasses=c(\"numeric\", \"numeric\", \"numeric\", \"numeric\", \"factor\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c95b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(myData)\n",
    "dim(myData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed704231",
   "metadata": {},
   "outputs": [],
   "source": [
    "#créons l'ensemble de données d'apprentissage\n",
    "#utilizons 50% des données pour la apprentissage\n",
    "set.seed(1) #controlled randomness\n",
    "trainIndex <- sample(1:dim(myData)[1],size=0.5*dim(myData)[1])\n",
    "trainData <- myData[trainIndex,]\n",
    "print(\"Train data\")\n",
    "head(trainData)\n",
    "dim(trainData)\n",
    "\n",
    "#et utilisons les restantes pour créer l'ensemble de test\n",
    "testData <- myData[-trainIndex,]\n",
    "print(\"Test data\")\n",
    "head(testData)\n",
    "dim(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599e90f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train a Naive Bayes on myData.\n",
    "#The parameter:\n",
    "# formula=result~.\n",
    "#sets the target/class variable to be the type.\n",
    "#and use as predictive variables all the others\n",
    "#Entraîner un Naive Bayes sur myData.\n",
    "#Le paramètre :\n",
    "# formula=result~.\n",
    "#définit la variable cible/classe comme étant le result\n",
    "#et utilise comme variables prédictives toutes les autres variables\n",
    "nb<-naiveBayes(formula=type~.,data=trainData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94eeca56-3538-4140-bd71-44a0763ed615",
   "metadata": {},
   "source": [
    "## évaluation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81158ae-0848-4efa-8e4b-b33237f56042",
   "metadata": {},
   "source": [
    "actement la même logique que pour les attributs qualitatifs, rien ne change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416ac654-f0cf-4fbc-aca7-bc120305da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testons le modèle entraîné sur l'ensemble de test que nous avons créé\n",
    "#predict prend en entrée :\n",
    "# * le modèle (nb)\n",
    "# * l'ensemble de test (testData)\n",
    "#et produit une prédiction pour chaque instance de test\n",
    "predictions <- predict(nb, testData)\n",
    "numCorrect <- sum(diag(table(testData[,5],predictions)))\n",
    "TBC <- numCorrect/nrow(testData)\n",
    "TBC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6193930-aa4f-46c4-9ba4-7c1c20044946",
   "metadata": {},
   "source": [
    "## Que contient le modèle de Naive Bayes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbfd49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voyons ce que nous avons dans le modèle\n",
    "nb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1be9351",
   "metadata": {},
   "source": [
    "========================================================================\n",
    "\n",
    "Les composantes du modèle ont la signification/interprétation suivante :\n",
    "\n",
    "========================================================================\n",
    "\n",
    "```A-priori probabilities:\n",
    "Y\n",
    "    Iris_setosa Iris_versicolor  Iris_virginica       => Y=type, la variable cible\n",
    "      0.3733333       0.2666667       0.3600000       => P(type) = {P(setosa),P(versicolor),P(virginica)}\n",
    "\n",
    "Conditional probabilities:\n",
    "                 sepal_length                         => P(sepal_length|type)\n",
    "Y                     [,1]      [,2]\n",
    "  Iris_setosa     4.978571 0.3541888                  => Moyenne, ecart-type de Sepal_length dans Setosa\n",
    "  Iris_versicolor 5.975000 0.4540751                  => Moyenne, ecart-type de Sepal_length dans Versicolor\n",
    "  Iris_virginica  6.748148 0.6441275                  => Moyenne, ecart-type de Sepal_length dans Virginica\n",
    "\n",
    "                 sepal_width                          => P(sepal_width|type)\n",
    "Y                     [,1]      [,2]\n",
    "  Iris_setosa     3.414286 0.3960119                  => Moyenne, ecart-type de Sepal_width dans Setosa\n",
    "  Iris_versicolor 2.810000 0.2174009                  => Moyenne, ecart-type de Sepal_width dans Versicolor\n",
    "  Iris_virginica  2.988889 0.3693376                  => Moyenne, ecart-type de Sepal_width dans Virginica\n",
    "\n",
    "                 petal_length                         => P(petal_length|type)\n",
    "Y                     [,1]      [,2]\n",
    "  Iris_setosa     1.464286 0.2022362                  => etc... \n",
    "  Iris_versicolor 4.395000 0.4135533\n",
    "  Iris_virginica  5.637037 0.6245910\n",
    "\n",
    "                 petal_width                          => P(petal_width|type)\n",
    "Y                      [,1]      [,2]\n",
    "  Iris_setosa     0.2607143 0.1257254                 => etc...\n",
    "  Iris_versicolor 1.3400000 0.1788854\n",
    "  Iris_virginica  2.0296296 0.2700638\n",
    "  \n",
    "  ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef2a9a9",
   "metadata": {},
   "source": [
    "**Remarque**: Comme nous le voyons (et nous nous y attendions), avec des attributs continus, nous nous appuierons sur leur moyenne et leur écart-type conditionnelle. Pour calculer la « probabilité » conditionnelle sachant la class, nous utiliserons maintenant la loi normale, dont la moyenne et l'ecart-type. \n",
    "\n",
    "Ainsi, si nous voulons calculer la P(petal_width | setosa ) pour une instance donnée, nous l' obtiendrons comme suit: \n",
    "\n",
    "\\begin{align}\n",
    "P(\\text{petalwidth} | \\text{setosa} )  = N( \\text{petalwidth};\\mu_{\\text{petalwidth|setosa}}, \\sigma^2_\\text{petalwidth|setosa})& \n",
    "=\\frac{1}{\\sqrt{2 \\pi \\sigma_{\\text{petalwidth|setosa}}^2}} \\exp{-\\frac{(\\text{petalwidth} - \\mu_{\\text{petalwidth|setosa}})^2}{2 * \\sigma_{\\text{petalwidth|setosa}}^2}} \\\\\n",
    "& =\\frac{1}{\\sqrt{2 \\pi 0.1257254^2}} \\exp{-\\frac{(\\text{petalwidth} - 0.2607143)^2}{2 * 0.1257254^2}}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Nous n'avons donc plus de tables de probabilités conditionnelles comme on avait pour les variables qualitatives, mais les moyennes et les écarts types conditionnels par classe que nous devons utiliser avec la densité gaussienne afin d'obtenir les probabilités conditionnelles dont nous avons besoin. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c45ce6b",
   "metadata": {},
   "source": [
    "Nous pouvons récupérer les différentes parties du modèle comme suit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b9299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#récupérer les comptes de la variable cible\n",
    "nb$apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d70270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#récupérer les \"propabilités conditionnelles\" étant donné la variable cible, cad P(x|y)\n",
    "# * propabilités conditionnelles pour les attributs qualitatifs (titanic)\n",
    "# * moyennes et écarts types conditionnels de classe pour les attributs quantitatifs (iris)\n",
    "\n",
    "nb$tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b8d218",
   "metadata": {},
   "source": [
    "Examinons donc de plus près l'une de ces tables, par exemple ```nb$tables$petal_width```. Ce tableau contient tout ce dont nous avons besoin pour construire les trois distributions conditionnelles $P(\\text{petalwidth}|\\text{setosa})$, $P(\\text{petalwidth}|\\text{versicolor})$, $P(\\text{petalwidth}|\\text{virginica})$. Construisons-les et visualisons-les donc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd4baef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets draw the three conditional distributions\n",
    "\n",
    "#dnorm is the density function of a normal distribution with mean=0 and sd=1\n",
    "#curve draws the dnorm function from=minimum of petal width+some epsillo to=maximum of petal width + some epsillon, \n",
    "#                               the epsillon is there to have a range that includes all the possible values of petal_width\n",
    "epsillon <- 0.7*(abs(min(myData[,4])-max(myData[,4])))\n",
    "\n",
    "#1. P(petal_width | setosa), using the means and the standard deviations that NB has already computed\n",
    "m<-nb$tables$petal_width[1,1] #retrieve the mean of petal_width in setosa\n",
    "s<-nb$tables$petal_width[1,2] #retrieve the std of petal_width in setosa\n",
    "curve(dnorm(x,mean=m, sd=s), from=min(myData[,4])-epsillon, to=max(myData[,4])+epsillon, col=2, lty=2,lwd=2, ylab=\"Density\", main=\"p(petal_width|setosa)\", xlab=\"petal_witdth\")\n",
    "text(x=0.5,y=3, labels=TeX(\"$N(z;\\\\mu_{setosa},\\\\sigma_{setosa}^2)=\\\\frac{1}{\\\\sqrt{2 \\\\pi \\\\sigma_{setosa}^2}} \\\\exp{-\\\\frac{(z - \\\\mu_{setosa})^2}{2\\\\sigma_{setosa}^2}}$\") )\n",
    "labelForMeanStd <- paste(\"$\\\\mu_{setosa}=\",m, \"\\\\ \\\\ \\\\ \\\\ \\\\sigma_{setosa}=\",s,\",$\")\n",
    "text(x=0.4,y=2.6, labels=TeX(labelForMeanStd))\n",
    "\n",
    "#2. P(petal_width | versicolor), using the means and the standard deviations that NB has already computed\n",
    "m<-nb$tables$petal_width[2,1] #retrieve the mean of petal_width in versicolor\n",
    "s<-nb$tables$petal_width[2,2] #retrieve the std of petal_width in versicolor\n",
    "curve(dnorm(x,mean=m, sd=s), from=min(myData[,4])-epsillon, to=max(myData[,4])+epsillon, col=3, lty=2,lwd=2, ylab=\"Density\", main=\"p(petal_width|versicolor)\", xlab=\"petal_width\")\n",
    "text(x=0.5,y=2, labels=TeX(\"$N(z;\\\\mu_{versicolor},\\\\sigma_{versicolor}^2)=\\\\frac{1}{\\\\sqrt{2 \\\\pi \\\\sigma_{versicolor}^2}} \\\\exp{-\\\\frac{(z - \\\\mu_{versicolor})^2}{2\\\\sigma_{versicolor}^2}}$\") )\n",
    "labelForMeanStd <- paste(\"$\\\\mu_{versicolor}=\",m, \"\\\\ \\\\ \\\\ \\\\ \\\\sigma_{versicilor}=\",s,\",$\")\n",
    "text(x=0.1,y=1.7, labels=TeX(labelForMeanStd))\n",
    "\n",
    "\n",
    "#2. P(petal_width | versicolor), using the means and the standard deviations that NB has already computed\n",
    "m<-nb$tables$petal_width[3,1] #retrieve the mean of petal_width in virginica\n",
    "s<-nb$tables$petal_width[3,2] #retrieve the std of petal_width in virginica\n",
    "curve(dnorm(x,mean=m, sd=s), from=min(myData[,4])-epsillon, to=max(myData[,4])+epsillon, col=4, lty=2,lwd=2, ylab=\"Density\", main=\"p(petal_width|virginica)\", xlab=\"petal_width\")\n",
    "text(x=0.5,y=1.4, labels=TeX(\"$N(z;\\\\mu_{virginica},\\\\sigma_{virginica}^2)=\\\\frac{1}{\\\\sqrt{2 \\\\pi \\\\sigma_{virginica}^2}} \\\\exp{-\\\\frac{(z - \\\\mu_{virginica})^2}{2\\\\sigma_{virginica}^2}}$\") )\n",
    "labelForMeanStd <- paste(\"$\\\\mu_{virginica}=\",m, \"\\\\ \\\\ \\\\ \\\\ \\\\sigma_{virginica}=\",s,\",$\")\n",
    "text(x=0.4,y=1.2, labels=TeX(labelForMeanStd))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6504cd7",
   "metadata": {},
   "source": [
    "Nous pouvons considérer que ces trois distributions conditionnelles correspondent aux tables de distribution conditionnelle que nous avions dans le cas de Titanic, par exemple les distributions conditionnelles de l'attribut âge compte tenu du résultat, $P(\\text{age}|\\text{result})$, qui étaient les suivantes\n",
    "\n",
    "```\n",
    "P(age|result)\n",
    "      age\n",
    "Y             adu        enf\n",
    "  mort 0.96513250 0.03486750\n",
    "  surv 0.92428198 0.07571802\n",
    "  ```\n",
    "  \n",
    "<img src=\"P.age.given.result.png\" alt=\"P(age|result)\"  width=\"300\" height=\"200\">\n",
    "\n",
    "Nous pouvons considérer chacune des barres comme l'équivalent des distributions conditionnelles que nous avons tracées ci-dessus pour chacune des classes. Dans le cas des attributs qualitatifs, les tableaux nous donnent directement la probabilité d'une valeur particulière, tandis que dans le cas des attributs quantitatifs, nous calculons cette probabilité à l'aide de la distribution gaussienne. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f96538",
   "metadata": {},
   "source": [
    "Ainsi, dans le cas d'attributs quantitatifs, nous devons utiliser la densité gaussienne pour calculer les probabilités conditionnelles. On peut se demander dans quelle mesure cettes probabilités sont exactes. La réponse dépend de la pertinence de l'hypothèse d'une distribution gaussienne. Nous pouvons vérifier cette hypothèse en traçant la distribution réelle des données, en utilisant les histogrammes et en les comparant aux densités respectives. C'est ce que nous allons faire ci-desous pour la conditionnelle\n",
    "\n",
    "\\begin{align}\n",
    "p(\\text{petalwidth}|\\text{type})=\\{p(\\text{petalwidth}|\\text{setosa}), p(\\text{petalwidth}|\\text{versicolor}), p(\\text{petalwidth}|\\text{virginica})\\}\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d976a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the code is more or less the same as above where we draw the conditional distributions as these are assumed\n",
    "#by the naive bayes model to be Gaussians, but now we also add the empirical estimates of these distributions\n",
    "#as there are given by the data and the respective histograms.\n",
    "\n",
    "#breaks for the histrograms\n",
    "minX <- min(myData[,4])\n",
    "maxX <- max(myData[,4])\n",
    "breaks = seq(from = minX, to = maxX, length.out=20)\n",
    "\n",
    "\n",
    "#lets draw the three conditional distributions\n",
    "\n",
    "#dnorm is the density function of a normal distribution with mean=0 and sd=1\n",
    "#curve draws the dnorm function from=minimum of petal width+some epsillo to=maximum of petal width + some epsillon, \n",
    "#                               the epsillon is there to have a range that includes all the possible values of petal_width\n",
    "epsillon <- 0.7*(abs(min(myData[,4])-max(myData[,4])))\n",
    "\n",
    "#1. P(petal_width | setosa), using the means and the standard deviations that NB has already computed\n",
    "m<-nb$tables$petal_width[1,1] #retrieve the mean of petal_width in setosa\n",
    "s<-nb$tables$petal_width[1,2] #retrieve the std of petal_width in setosa\n",
    "curve(dnorm(x,mean=m, sd=s), from=min(myData[,4])-epsillon, to=max(myData[,4])+epsillon, col=2, lty=2,lwd=2, ylab=\"Density\", main=\"p(petal_width|setosa)\", xlab=\"petal_witdth\", ylim=c(0,6))\n",
    "#text(x=-2,y=1.5, labels=TeX(\"$N(\\\\mu_{setosa},\\\\sigma_{setosa}^2)=\\\\frac{1}{\\\\sqrt{2 \\\\pi \\\\sigma_{setosa}^2}} \\\\exp{-\\\\frac{(z - \\\\mu_{setosa})^2}{2\\\\sigma_{setosa}^2}}$\") )\n",
    "#labelForMeanStd <- paste(\"$\\\\mu_{setosa}=\",m, \"\\\\ \\\\ \\\\ \\\\ \\\\sigma_{setosa}=\",s,\",$\")\n",
    "#text(x=-2.2,y=1.3, labels=TeX(labelForMeanStd))\n",
    "hist(myData[myData[,5]==\"Iris_setosa\",4],breaks=breaks, freq=FALSE, add=TRUE)\n",
    "\n",
    "\n",
    "#2. P(petal_width | versicolor), using the means and the standard deviations that NB has already computed\n",
    "m<-nb$tables$petal_width[2,1] #retrieve the mean of petal_width in versicolor\n",
    "s<-nb$tables$petal_width[2,2] #retrieve the std of petal_width in versicolor\n",
    "curve(dnorm(x,mean=m, sd=s), from=min(myData[,4])-epsillon, to=max(myData[,4])+epsillon, col=3, lty=2,lwd=2, ylab=\"Density\", main=\"p(petal_width|versicolor)\", xlab=\"petal_width\", ylim=c(0,4.5))\n",
    "#text(x=-1.2,y=0.28, labels=TeX(\"$N(\\\\mu_{versicolor},\\\\sigma_{versicolor}^2)=\\\\frac{1}{\\\\sqrt{2 \\\\pi \\\\sigma_{versicolor}^2}} \\\\exp{-\\\\frac{(z - \\\\mu_{versicolor})^2}{2\\\\sigma_{versicolor}^2}}$\") )\n",
    "#labelForMeanStd <- paste(\"$\\\\mu_{versicolor}=\",m, \"\\\\ \\\\ \\\\ \\\\ \\\\sigma_{versicilor}=\",s,\",$\")\n",
    "#text(x=-3,y=0.25, labels=TeX(labelForMeanStd))\n",
    "hist(myData[myData[,5]==\"Iris_versicolor\",4],breaks=breaks, freq=FALSE, add=TRUE)\n",
    "\n",
    "\n",
    "#3. P(petal_width | versicolor), using the means and the standard deviations that NB has already computed\n",
    "m<-nb$tables$petal_width[3,1] #retrieve the mean of petal_width in virginica\n",
    "s<-nb$tables$petal_width[3,2] #retrieve the std of petal_width in virginica\n",
    "curve(dnorm(x,mean=m, sd=s), from=min(myData[,4])-epsillon, to=max(myData[,4])+epsillon, col=4, lty=2,lwd=2, ylab=\"Density\", main=\"p(petal_width|virginica)\", xlab=\"petal_width\", ylim=c(0,4.5))\n",
    "#text(x=-1.2,y=0.18, labels=TeX(\"$N(\\\\mu_{virginica},\\\\sigma_{virginica}^2)=\\\\frac{1}{\\\\sqrt{2 \\\\pi \\\\sigma_{virginica}^2}} \\\\exp{-\\\\frac{(z - \\\\mu_{virginica})^2}{2\\\\sigma_{virginica}^2}}$\") )\n",
    "#labelForMeanStd <- paste(\"$\\\\mu_{virginica}=\",m, \"\\\\ \\\\ \\\\ \\\\ \\\\sigma_{virginica}=\",s,\",$\")\n",
    "#text(x=-2.9,y=0.16, labels=TeX(labelForMeanStd))\n",
    "hist(myData[myData[,5]==\"Iris_virginica\",4],breaks=breaks, freq=FALSE, add=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65da46f",
   "metadata": {},
   "source": [
    "Comme le montrent les figures, l'hypothèse d'une distribution gaussienne n'est pas très précise/appropriée. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1694e02d",
   "metadata": {},
   "source": [
    "### Partie théorique de Naive Bayes : comprendre comment le modèle classifie/calcule les probabilités"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44498ff",
   "metadata": {},
   "source": [
    "La logique est exactement la même que dans le cas des attributs quantitatifs ; la seule différence réside dans la manière dont les probabilités conditionnelles sont calculées. Comme nous l'avons déjà dit dans le cas des attributs quantitatifs, nous ne disposons pas de tables de probabilités conditionnelles par classe, mais de moyennes et d'écarts types conditionnels par classe que nous utilisons avec la distribution gaussienne pour obtenir les probabilités conditionnelles par classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27319c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examinons un instance de test particulier, par exemple le premier\n",
    "testInstance<-testData[1,]\n",
    "testInstance\n",
    "#et les probabilités prédites de mort et de surv\n",
    "pred1 <- predict(nb, testData[1,],type = \"raw\")\n",
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b17188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualisons la distribution des probabilites de result sachant l' instance: first, adu, m\n",
    "#cad la distribution a posteriori: de P(result|first, adu, m)\n",
    "barplot(pred1, main=paste(\"P(type|\",paste(testInstance, collapse=\" \"),\")\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1c734a",
   "metadata": {},
   "source": [
    "et voyons comment Naive Bayes utilise les différentes  distributions qu'il a calculées, cad: \n",
    "$$ P(\\text{sepallength}|\\text{type}), P(\\text{sepalwidth}|\\text{type}), P(\\text{petalwidth}|\\text{type}), P(\\text{petalwidth}|\\text{type}), P(\\text{type}) $$\n",
    "pour calculer ces trois probabilités, cad pour calculer:\n",
    "$$P(\\text{type}|\\mathbf x) = \\{ P(\\text{type}=\\text{setosa} |\\mathbf x), P(\\text{type}=\\text{virginica} |\\mathbf x)  P(\\text{type}=\\text{versicolor} |\\mathbf x) \\}$$\n",
    "pour notre $\\mathbf x = (5.1, 3.5, 1.4, 0.2\t)$.\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    " P(\\text{setosa} | 5.1, 3.5, 1.4, 0.2) & =\\frac{P(5.1, 3.5, 1.4, 0.2|\\text{setosa}) P(\\text{setosa})}{P(5.1, 3.5, 1.4, 0.2)} \\\\\n",
    "  = & \\frac{P(5.1|\\text{setosa}) P(3.5|\\text{setosa})\n",
    " \\times    P(1.4|\\text{setosa}) P(0.2|\\text{setosa}) \n",
    " \\times P(\\text{setosa})} \n",
    " {P(5.1, 3.5, 1.4, 0.2)}\n",
    "\\end{align}\n",
    "\n",
    "la seule différence par rapport au cas des attributs qualitatifs est que, comme nous l'avons dit, nous n'avons plus de tables de probabilités conditionnelles que nous utilisons pour obtenir les probabilités dont nous avons besoin, mais nous les calculerons en utilisant la distribution gaussienne et les moyennes et écarts-types conditionnels de classe appropriés. Donc\n",
    "\n",
    "\\begin{align} \n",
    "\\frac{P(5.1|\\text{setosa}) P(3.5|\\text{setosa})\n",
    " \\times    P(1.4|\\text{setosa}) P(0.2|\\text{setosa}) \n",
    " \\times P(\\text{setosa})} \n",
    " {P(5.1, 3.5, 1.4, 0.2)} = \n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "\\small\n",
    "  \\frac{N(5.1;\\mu_{\\text{sepallength|setosa}},\\sigma^2_{\\text{sepallength|setosa}}) \\times  \\\\\n",
    "           N(3.5;\\mu_{\\text{sepalwidth|setosa}},\\sigma^2_{\\text{sepalwidth|setosa}}) \\times \\\\\n",
    "           N(1.4;\\mu_{\\text{petallength|setosa}},\\sigma^2_{\\text{petallength|setosa}}) \\times \\\\\n",
    "           N(0.2;\\mu_{\\text{petalwidth|setosa}},\\sigma^2_{\\text{petalwidth|setosa}}) \\times P(\\text{setosa}) \n",
    "           }{P(5.1, 3.5, 1.4, 0.2)}\n",
    "\\end{align}\n",
    "\n",
    "Nous pouvons très facilement obtenir chacun des termes : \n",
    "* $N(5.1;\\mu_{\\text{sepallength|setosa}},\\sigma^2_{\\text{sepallength|setosa}})=\\frac{1}{\\sqrt{2 \\pi \\sigma_{\\text{sepallength|setosa}}^2}} \\exp{-\\frac{(5.1 - \\mu_{\\text{sepallength|setosa}})^2}{2\\sigma_{\\text{sepallength|setosa}}^2}}$\n",
    "* $N(3.5;\\mu_{\\text{sepalwidth|setosa}},\\sigma^2_{\\text{sepalwidth|setosa}})=\\frac{1}{\\sqrt{2 \\pi \\sigma_{\\text{sepalwidth|setosa}}^2}} \\exp{-\\frac{(3.5 - \\mu_{\\text{sepalwidth|setosa}})^2}{2\\sigma_{\\text{sepalwidth|setosa}}^2}}$\n",
    "* $N(1.4;\\mu_{\\text{petallength|setosa}},\\sigma^2_{\\text{petallength|setosa}})=\\frac{1}{\\sqrt{2 \\pi \\sigma_{\\text{petallength|setosa}}^2}} \\exp{-\\frac{(1.4 - \\mu_{\\text{petallength|setosa}})^2}{2\\sigma_{\\text{petallength|setosa}}^2}}$\n",
    "* $N(0.2;\\mu_{\\text{petalwidth|setosa}},\\sigma^2_{\\text{petalwidth|setosa}})=\\frac{1}{\\sqrt{2 \\pi \\sigma_{\\text{petalwidth|setosa}}^2}} \\exp{-\\frac{(0.2 - \\mu_{\\text{petalwidth|setosa}})^2}{2\\sigma_{\\text{petalwidth|setosa}}^2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81eb613",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets just compute the first one: P(sepal_length=5.1|setosa)\n",
    "m<-nb$tables$sepal_length[1,1]\n",
    "s<-nb$tables$sepal_length[1,2]\n",
    "\n",
    "#compute now the density N(5.1;m,s)\n",
    "dnorm(5.1,m,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178e1b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#and lets visualise this probability/density\n",
    "#P(sepal length | setosa), and its evaluation at sepal_length=5.1\n",
    "epsillon <- (abs(min(myData[myData[,5]==\"Iris_setosa\",1])-max(myData[myData[,5]==\"Iris_setosa\",1])))\n",
    "curve(dnorm(x,mean=m, sd=s), from=min(myData[myData[,5]==\"Iris_setosa\",1])-epsillon, to=max(myData[myData[,5]==\"Iris_setosa\",1])+epsillon, col=2, lty=2,lwd=2, ylab=\"Density\", main=\"p(sepal_length|setosa)\", xlab=\"sepal_length\", ylim=c(0,1.5))\n",
    "text(x=-2,y=1.5, labels=TeX(\"$N(\\\\mu_{setosa},\\\\sigma_{setosa}^2)=\\\\frac{1}{\\\\sqrt{2 \\\\pi \\\\sigma_{setosa}^2}} \\\\exp{-\\\\frac{(z - \\\\mu_{setosa})^2}{2\\\\sigma_{setosa}^2}}$\") )\n",
    "labelForMeanStd <- paste(\"$\\\\mu_{setosa}=\",m, \"\\\\ \\\\ \\\\ \\\\ \\\\sigma_{setosa}=\",s,\",$\")\n",
    "text(x=-2.2,y=1.3, labels=TeX(labelForMeanStd))\n",
    "\n",
    "#plot the point that corresponds to petal_length=5.1\n",
    "points(x=5.1,y=0)\n",
    "\n",
    "#and show its corresponding density\n",
    "points(x=c(5.1,5.1),y=c(0,dnorm(5.1,m,s)),col=\"red\",type=\"l\")\n",
    "points(x=5.1,y=dnorm(5.1,m,s))\n",
    "text(x=6,y=dnorm(5.1,m,s), labels=\"P(sepal_length=5.1|setosa)\",col=\"darkred\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb7d345",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd74890",
   "metadata": {},
   "source": [
    "**Exercise** Entraîner un modèle naïf de Bayes sur 70% de l'ensemble de données d'iris, en utilisant uniquement les attributs sepal_length et petal_length et uniquement les deux classes : virginica et versicolor. Extraire et visualiser les distributions suivantes à partir du modèle\n",
    "\n",
    "* P(type)\n",
    "* P(sepal_length|type)\n",
    "* P(petal_length|type)\n",
    "\n",
    "Utilisez les distributions ci-dessus pour expliquer comment le modèle Naive Bayes calculera la probabilité de setosa pour l'instance $\\mathbf x = (6.9, 3.1)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146e87f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here\n",
    "#creates the simpler iris\n",
    "reducedIris <- myData[myData[,5]!=\"Iris_setosa\",c(1,3,5)]\n",
    "\n",
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954d0ba9",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76502827",
   "metadata": {},
   "source": [
    "A somehow more generic (though not very generic) function that plots in one go all conditional distributions for all attributes as these are given by the naive bayes model. It assumes that all attributes are numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a0e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using colorspace Package, which allows to control colors transperancy\n",
    "#while indexing colors with integer indeces\n",
    "#Install and load the colorspace package if you haven't already\n",
    "package_name <- \"colorspace\"\n",
    "# Check if the package is installed\n",
    "if (!require(package_name, character.only = TRUE)) {\n",
    "    install.packages(package_name)\n",
    "}\n",
    "library(package_name, character.only = TRUE)\n",
    "\n",
    "#receives as input:\n",
    "# * myData : the dataset\n",
    "# * nb : a naive bayes model trained on that dataset\n",
    "# * classColIndex : the index of the class attributes\n",
    "# it will plot the all class conditional distributions for each attribute\n",
    "# Attention: it assumes that all attributes are numeric\n",
    "condDist <- function(myData, nb, classColIndex){\n",
    "\n",
    "    numAttrs <- dim(myData)[1]-1\n",
    "    numClasses<-length(unique(myData[,classColIndex]))\n",
    "\n",
    "    \n",
    "    for (attribute in 1:length(nb$tables)) {\n",
    "\n",
    "        par(mfrow = c(1,2))\n",
    "    \n",
    "        condDistStats<-nb$tables[[attribute]]\n",
    "        attrName    <- names(nb$tables[attribute])\n",
    "        numClasses  <- nrow(condDistStats)\n",
    "        classNames <- rownames(condDistStats)\n",
    "    \n",
    "    \n",
    "        minVal <- min(myData[,attribute])\n",
    "        maxVal <- max(myData[,attribute])\n",
    "\n",
    "        epsillon <- (abs(minVal-maxVal))\n",
    "    \n",
    "        breaks = seq(from = minVal-epsillon, to = maxVal+epsillon, length.out=30)\n",
    "    \n",
    "\n",
    "        #go over the classes\n",
    "        add=FALSE #first time in the loop add = False to create a new figure\n",
    "        for(classIndex in 1:numClasses){\n",
    "            m<-condDistStats[classIndex,1] #retrieve the mean of petal_width in setosa\n",
    "            s<-condDistStats[classIndex,2] #retrieve the std of petal_width in setosa\n",
    "            className <- classNames[classIndex]\n",
    "            curve(dnorm(x,mean=m, sd=s), \n",
    "                  from=minVal-epsillon, to=maxVal+epsillon, \n",
    "                  col=classIndex, lty=2,lwd=2, \n",
    "                  ylab=\"Density\", \n",
    "                  main=paste(\"p(\",attrName,\"|\",names(myData)[classColIndex],\")\"), \n",
    "                  xlab=attrName, add=add)\n",
    "            add=TRUE\n",
    "        }\n",
    "        legend(\"topright\", legend=classNames,fill=1:numClasses)\n",
    "     \n",
    "        add=FALSE\n",
    "        for(classIndex in 1:numClasses){\n",
    "            className <- classNames[classIndex]\n",
    "            transparentColor <- adjust_transparency(palette()[classIndex], alpha = 0.5) #adds transparency for better visuals\n",
    "            hist(myData[myData[,classColIndex]==className,attribute],\n",
    "             breaks=breaks,\n",
    "             add=add,col=transparentColor, \n",
    "             main=paste(\"p(\",attrName,\"|\",names(myData)[classColIndex],\")\"), \n",
    "             xlab=attrName)\n",
    "            add=TRUE\n",
    "        }\n",
    "        legend(\"topright\", legend=classNames,fill=1:numClasses)\n",
    "\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c7da88",
   "metadata": {},
   "outputs": [],
   "source": [
    "condDist(myData,nb,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2759ad38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b7e666-e1f0-4c1b-a78b-5f0e2ad1c4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe203d7b-db0d-4232-b9af-d85d277495c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74586a07-e321-4c3f-a451-974969a0a579",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
